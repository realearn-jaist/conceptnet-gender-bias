{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ9RdOJJPNw0",
        "outputId": "380539e9-8009-4e5a-d3d6-e969219c5fe6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Khine/kge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sy_6elTms01",
        "outputId": "97a0342b-e36a-42aa-ed16-59e4e5d85932"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Khine/kge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "id": "_8EjzDZ3MXD3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c2252f13-fc37-4738-b5be-bc656a05e1df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/drive/MyDrive/Khine/kge\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from libkge==0.1) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from libkge==0.1) (2.0.1+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from libkge==0.1) (6.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from libkge==0.1) (1.5.3)\n",
            "Collecting argparse (from libkge==0.1)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting path (from libkge==0.1)\n",
            "  Downloading path-16.7.1-py3-none-any.whl (25 kB)\n",
            "Collecting ax-platform>=0.1.19 (from libkge==0.1)\n",
            "  Downloading ax_platform-0.3.4-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botorch>=0.4.0 (from libkge==0.1)\n",
            "  Downloading botorch-0.9.2-py3-none-any.whl (567 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.8/567.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpytorch>=1.4.2 (from libkge==0.1)\n",
            "  Downloading gpytorch-1.11-py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlalchemy<2.0.0 (from libkge==0.1)\n",
            "  Downloading SQLAlchemy-1.4.49-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchviz (from libkge==0.1)\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba>=0.50.0 in /usr/local/lib/python3.10/dist-packages (from libkge==0.1) (0.56.4)\n",
            "Collecting hpbandster (from libkge==0.1)\n",
            "  Downloading hpbandster-0.7.4.tar.gz (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ConfigSpace (from libkge==0.1)\n",
            "  Downloading ConfigSpace-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest-shutil (from libkge==0.1)\n",
            "  Downloading pytest_shutil-1.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting igraph (from libkge==0.1)\n",
            "  Downloading igraph-0.10.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from ax-platform>=0.1.19->libkge==0.1) (3.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ax-platform>=0.1.19->libkge==0.1) (1.11.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ax-platform>=0.1.19->libkge==0.1) (1.2.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from ax-platform>=0.1.19->libkge==0.1) (7.7.1)\n",
            "Requirement already satisfied: plotly>=5.12.0 in /usr/local/lib/python3.10/dist-packages (from ax-platform>=0.1.19->libkge==0.1) (5.15.0)\n",
            "Collecting typeguard==2.13.3 (from ax-platform>=0.1.19->libkge==0.1)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from botorch>=0.4.0->libkge==0.1) (1.0.0)\n",
            "Collecting pyro-ppl>=1.8.4 (from botorch>=0.4.0->libkge==0.1)\n",
            "  Downloading pyro_ppl-1.8.6-py3-none-any.whl (732 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.8/732.8 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting linear-operator==0.5.1 (from botorch>=0.4.0->libkge==0.1)\n",
            "  Downloading linear_operator-0.5.1-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.5/174.5 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jaxtyping>=0.2.9 (from linear-operator==0.5.1->botorch>=0.4.0->libkge==0.1)\n",
            "  Downloading jaxtyping-0.2.21-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.50.0->libkge==0.1) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.50.0->libkge==0.1) (67.7.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2.0.0->libkge==0.1) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->libkge==0.1) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->libkge==0.1) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->libkge==0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->libkge==0.1) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->libkge==0.1) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.1->libkge==0.1) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.1->libkge==0.1) (16.0.6)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->libkge==0.1) (3.1.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->libkge==0.1) (10.1.0)\n",
            "Collecting Pyro4 (from hpbandster->libkge==0.1)\n",
            "  Downloading Pyro4-4.82-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting serpent (from hpbandster->libkge==0.1)\n",
            "  Downloading serpent-1.41-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from hpbandster->libkge==0.1) (0.14.0)\n",
            "Collecting netifaces (from hpbandster->libkge==0.1)\n",
            "  Downloading netifaces-0.11.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting texttable>=1.6.2 (from igraph->libkge==0.1)\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->libkge==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->libkge==0.1) (2023.3.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pytest-shutil->libkge==0.1) (1.16.0)\n",
            "Collecting execnet (from pytest-shutil->libkge==0.1)\n",
            "  Downloading execnet-2.0.2-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from pytest-shutil->libkge==0.1) (21.6.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from pytest-shutil->libkge==0.1) (7.4.1)\n",
            "Collecting path.py (from pytest-shutil->libkge==0.1)\n",
            "  Downloading path.py-12.5.0-py3-none-any.whl (2.3 kB)\n",
            "Collecting mock (from pytest-shutil->libkge==0.1)\n",
            "  Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pytest-shutil->libkge==0.1) (2.3.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz->libkge==0.1) (0.20.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.12.0->ax-platform>=0.1.19->libkge==0.1) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=5.12.0->ax-platform>=0.1.19->libkge==0.1) (23.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch>=0.4.0->libkge==0.1) (3.3.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.8.4->botorch>=0.4.0->libkge==0.1)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch>=0.4.0->libkge==0.1) (4.66.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ax-platform>=0.1.19->libkge==0.1) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ax-platform>=0.1.19->libkge==0.1) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ax-platform>=0.1.19->libkge==0.1) (3.6.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ax-platform>=0.1.19->libkge==0.1) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ax-platform>=0.1.19->libkge==0.1) (3.0.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->ax-platform>=0.1.19->libkge==0.1) (2.1.3)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->pytest-shutil->libkge==0.1) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->pytest-shutil->libkge==0.1) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->pytest-shutil->libkge==0.1) (1.1.3)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->pytest-shutil->libkge==0.1) (2.0.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ax-platform>=0.1.19->libkge==0.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ax-platform>=0.1.19->libkge==0.1) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster->libkge==0.1) (0.5.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->libkge==0.1) (1.3.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (6.3.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1)\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (4.8.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.8.3)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (5.3.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (1.5.7)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.17.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (1.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.2.6)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (3.10.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.8.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (2.18.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (4.19.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.10.2)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (1.6.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform>=0.1.19->libkge==0.1) (2.21)\n",
            "Building wheels for collected packages: hpbandster, torchviz, netifaces\n",
            "  Building wheel for hpbandster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hpbandster: filename=hpbandster-0.7.4-py3-none-any.whl size=79988 sha256=3ea1963ba7828979af361228d195830024a74a00f16f316151587e05728de654\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/51/18/33d6ba8c55cc8401bffbccb1b87b21e0c68f40edc4ce3c1f99\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4130 sha256=b8395e1c62fe0913819169f016225a511cb0264539fbae0eb724bd72bf9dafa6\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for netifaces: filename=netifaces-0.11.0-cp310-cp310-linux_x86_64.whl size=35006 sha256=1c1b3f267cd9316f34584c5fa802b00369ce30cfdbde71e33e11fb66d7e9afd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/65/b3/4c4cc6038b81ff21cc9df69f2b6774f5f52e23d3c275ed15aa\n",
            "Successfully built hpbandster torchviz netifaces\n",
            "Installing collected packages: texttable, pyro-api, netifaces, argparse, typeguard, sqlalchemy, serpent, path, mock, jedi, igraph, execnet, Pyro4, path.py, jaxtyping, ConfigSpace, pytest-shutil, hpbandster, linear-operator, pyro-ppl, gpytorch, botorch, torchviz, ax-platform, libkge\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.20\n",
            "    Uninstalling SQLAlchemy-2.0.20:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.20\n",
            "  Running setup.py develop for libkge\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.49 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ConfigSpace-0.7.1 Pyro4-4.82 argparse-1.4.0 ax-platform-0.3.4 botorch-0.9.2 execnet-2.0.2 gpytorch-1.11 hpbandster-0.7.4 igraph-0.10.8 jaxtyping-0.2.21 jedi-0.19.0 libkge-0.1 linear-operator-0.5.1 mock-5.1.0 netifaces-0.11.0 path-16.7.1 path.py-12.5.0 pyro-api-0.1.2 pyro-ppl-1.8.6 pytest-shutil-1.7.0 serpent-1.41 sqlalchemy-1.4.49 texttable-1.6.7 torchviz-0.0.2 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-restart runtime."
      ],
      "metadata": {
        "id": "w_FwMeRI3Etc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Khine/kge/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBf4fHgs8Hf8",
        "outputId": "93bec08d-7e0c-42fc-a10b-1f0d25dd3202"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Khine/kge/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sh download_all.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-jOBqe28Ob_",
        "outputId": "ab88ace0-78f6-4016-9c6c-f78daca09581"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading toy\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 38267  100 38267    0     0  37887      0  0:00:01  0:00:01 --:--:-- 37925\n",
            "toy/train.txt\n",
            "toy/test.txt\n",
            "toy/valid.txt\n",
            "toy/README\n",
            "toy/entities.txt\n",
            "toy/\n",
            "toy/relations.txt\n",
            "Preprocessing toy...\n",
            "Found 4565 triples in train.txt\n",
            "Found 109 triples in valid.txt\n",
            "Found 152 triples in test.txt\n",
            "112 distinct relations\n",
            "280 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 152\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 152\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 4565\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 109\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 109\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 109\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: toy\n",
            "  num_entities: 280\n",
            "  num_relations: 112\n",
            "\n",
            "Downloading fb15k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 7680k  100 7680k    0     0   341k      0  0:00:22  0:00:22 --:--:--  359k\n",
            "fb15k/\n",
            "fb15k/freebase_mtr100_mte100-test.txt\n",
            "fb15k/README\n",
            "fb15k/freebase_mtr100_mte100-train.txt\n",
            "fb15k/freebase_mtr100_mte100-valid.txt\n",
            "fb15k/entity_strings.del\n",
            "Preprocessing fb15k...\n",
            "Found 483142 triples in train.txt\n",
            "Found 50000 triples in valid.txt\n",
            "Found 59071 triples in test.txt\n",
            "1345 distinct relations\n",
            "14951 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.entity_strings.filename: entity_strings.del\n",
            "  files.entity_strings.type: idmap\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 59071\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 59071\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 483142\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 50000\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 50000\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 50000\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: fb15k\n",
            "  num_entities: 14951\n",
            "  num_relations: 1345\n",
            "\n",
            "Downloading fb15k-237\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 3808k  100 3808k    0     0   319k      0  0:00:11  0:00:11 --:--:--  347k\n",
            "fb15k-237/\n",
            "fb15k-237/MSR-LA_Data_Full Rights_FB15K-237 Knowledge Base Completion Dataset (2650).docx\n",
            "fb15k-237/README.txt\n",
            "fb15k-237/valid.txt\n",
            "fb15k-237/train.txt\n",
            "fb15k-237/entity_strings.del\n",
            "fb15k-237/test.txt\n",
            "Preprocessing fb15k-237...\n",
            "Found 272115 triples in train.txt\n",
            "Found 17535 triples in valid.txt\n",
            "Found 20466 triples in test.txt\n",
            "237 distinct relations\n",
            "14541 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.entity_strings.filename: entity_strings.del\n",
            "  files.entity_strings.type: idmap\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 20466\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 20438\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 272115\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 17535\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 17535\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 17526\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: fb15k-237\n",
            "  num_entities: 14541\n",
            "  num_relations: 237\n",
            "\n",
            "Downloading wn18\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1822k  100 1822k    0     0   303k      0  0:00:06  0:00:06 --:--:--  359k\n",
            "wn18/wordnet-mlj12-train.txt\n",
            "wn18/\n",
            "wn18/README\n",
            "wn18/Wordnet3.0-LICENSE\n",
            "wn18/wordnet-mlj12-test.txt\n",
            "wn18/wordnet-mlj12-valid.txt\n",
            "wn18/entity_strings.del\n",
            "Preprocessing wn18...\n",
            "Found 141442 triples in train.txt\n",
            "Found 5000 triples in valid.txt\n",
            "Found 5000 triples in test.txt\n",
            "18 distinct relations\n",
            "40943 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.entity_strings.filename: entity_strings.del\n",
            "  files.entity_strings.type: idmap\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 5000\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 5000\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 141442\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 5000\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 5000\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 5000\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: wn18\n",
            "  num_entities: 40943\n",
            "  num_relations: 18\n",
            "\n",
            "Downloading wnrr\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1267k  100 1267k    0     0   299k      0  0:00:04  0:00:04 --:--:--  299k\n",
            "wnrr/test.txt\n",
            "wnrr/train.txt\n",
            "wnrr/valid.txt\n",
            "wnrr/\n",
            "wnrr/entity_strings.del\n",
            "Preprocessing wnrr...\n",
            "Found 86835 triples in train.txt\n",
            "Found 3034 triples in valid.txt\n",
            "Found 3134 triples in test.txt\n",
            "11 distinct relations\n",
            "40943 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.entity_strings.filename: entity_strings.del\n",
            "  files.entity_strings.type: idmap\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 3134\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 2924\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 86835\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 3034\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 3034\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 2824\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: wnrr\n",
            "  num_entities: 40943\n",
            "  num_relations: 11\n",
            "\n",
            "Downloading dbpedia50\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 6389k  100 6389k    0     0   335k      0  0:00:19  0:00:19 --:--:--  362k\n",
            "dbpedia50/kb2e/entity2id.txt\n",
            "dbpedia50/eval.tails.idx\n",
            "dbpedia50/entities.txt\n",
            "dbpedia50/train.txt\n",
            "dbpedia50/relations.txt\n",
            "dbpedia50/eval.heads.values.closed\n",
            "dbpedia50/eval.heads.idx\n",
            "dbpedia50/test.txt\n",
            "dbpedia50/kb2e/train.txt\n",
            "dbpedia50/train.tails.idx\n",
            "dbpedia50/vocab.txt\n",
            "dbpedia50/\n",
            "dbpedia50/avoid_entities.txt\n",
            "dbpedia50/eval.tails.values.open\n",
            "dbpedia50/train.heads.idx\n",
            "dbpedia50/relation_names.txt\n",
            "dbpedia50/kb2e/valid.txt\n",
            "dbpedia50/kb2e/\n",
            "dbpedia50/test.txt.orig\n",
            "dbpedia50/valid.txt.orig\n",
            "dbpedia50/kb2e/test.txt\n",
            "dbpedia50/train.heads.values\n",
            "dbpedia50/valid.txt\n",
            "dbpedia50/train.txt.orig\n",
            "dbpedia50/entity_names.txt\n",
            "dbpedia50/train.tails.values\n",
            "dbpedia50/eval.heads.values.open\n",
            "dbpedia50/kb2e/relation2id.txt\n",
            "dbpedia50/eval.tails.values.closed\n",
            "Preprocessing dbpedia50...\n",
            "Found 32388 triples in train.txt\n",
            "Found 399 triples in valid.txt\n",
            "Found 10969 triples in test.txt\n",
            "365 distinct relations\n",
            "30449 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 10969\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 2098\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 32388\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 399\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 399\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 123\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: dbpedia50\n",
            "  num_entities: 30449\n",
            "  num_relations: 365\n",
            "\n",
            "Downloading dbpedia500\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 51.8M  100 51.8M    0     0   347k      0  0:02:32  0:02:32 --:--:--  356k\n",
            "dbpedia500/valid.txt\n",
            "dbpedia500/\n",
            "dbpedia500/train.txt\n",
            "dbpedia500/test.txt\n",
            "Preprocessing dbpedia500...\n",
            "Found 3102677 triples in train.txt\n",
            "Found 10000 triples in valid.txt\n",
            "Found 1155937 triples in test.txt\n",
            "573 distinct relations\n",
            "490598 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 1155937\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 339621\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 3102677\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 10000\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 10000\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 4976\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: dbpedia500\n",
            "  num_entities: 490598\n",
            "  num_relations: 573\n",
            "\n",
            "Downloading db100k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 6223k  100 6223k    0     0   334k      0  0:00:18  0:00:18 --:--:--  362k\n",
            "db100k/_valid.txt\n",
            "db100k/_test.txt\n",
            "db100k/_train.txt\n",
            "db100k/_cons.txt\n",
            "db100k/\n",
            "Preprocessing db100k...\n",
            "Found 597572 triples in train.txt\n",
            "Found 50000 triples in valid.txt\n",
            "Found 50000 triples in test.txt\n",
            "470 distinct relations\n",
            "99604 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 50000\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 50000\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 597572\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 50000\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 50000\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 50000\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: db100k\n",
            "  num_entities: 99604\n",
            "  num_relations: 470\n",
            "\n",
            "Downloading yago3-10\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 18.4M  100 18.4M    0     0   344k      0  0:00:54  0:00:54 --:--:--  354k\n",
            "yago3-10/\n",
            "yago3-10/test.txt\n",
            "yago3-10/valid.txt\n",
            "yago3-10/train.txt\n",
            "Preprocessing yago3-10...\n",
            "Found 1079040 triples in train.txt\n",
            "Found 5000 triples in valid.txt\n",
            "Found 5000 triples in test.txt\n",
            "37 distinct relations\n",
            "123182 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 5000\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 4982\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 1079040\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 5000\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 5000\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 4978\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: yago3-10\n",
            "  num_entities: 123182\n",
            "  num_relations: 37\n",
            "\n",
            "Downloading wikidata5m\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  166M  100  166M    0     0   348k      0  0:08:09  0:08:09 --:--:--  354k\n",
            "wikidata5m/valid.txt\n",
            "wikidata5m/\n",
            "wikidata5m/train.txt\n",
            "wikidata5m/test.txt\n",
            "Preprocessing wikidata5m...\n",
            "Found 21343681 triples in train.txt\n",
            "Found 5357 triples in valid.txt\n",
            "Found 5321 triples in test.txt\n",
            "828 distinct relations\n",
            "4818679 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 5321\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 5144\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 21343681\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 5357\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 5357\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 5153\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: wikidata5m\n",
            "  num_entities: 4818679\n",
            "  num_relations: 828\n",
            "\n",
            "Downloading kinship\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 42816  100 42816    0     0  52159      0 --:--:-- --:--:-- --:--:-- 52151\n",
            "kinship/train.txt\n",
            "kinship/valid.txt\n",
            "kinship/test.txt\n",
            "kinship/\n",
            "Preprocessing kinship...\n",
            "Found 8544 triples in train.txt\n",
            "Found 1068 triples in valid.txt\n",
            "Found 1074 triples in test.txt\n",
            "25 distinct relations\n",
            "104 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 1074\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 1074\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 8544\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 1068\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 1068\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 1068\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: kinship\n",
            "  num_entities: 104\n",
            "  num_relations: 25\n",
            "\n",
            "Downloading nations\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  8044  100  8044    0     0   9477      0 --:--:-- --:--:-- --:--:--  9485\n",
            "nations/valid.txt\n",
            "nations/\n",
            "nations/test.txt\n",
            "nations/train.txt\n",
            "Preprocessing nations...\n",
            "Found 1592 triples in train.txt\n",
            "Found 199 triples in valid.txt\n",
            "Found 201 triples in test.txt\n",
            "55 distinct relations\n",
            "14 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 201\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 201\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 1592\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 199\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 199\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 199\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: nations\n",
            "  num_entities: 14\n",
            "  num_relations: 55\n",
            "\n",
            "Downloading umls\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 35710  100 35710    0     0  52417      0 --:--:-- --:--:-- --:--:-- 52437\n",
            "umls/test.txt\n",
            "umls/valid.txt\n",
            "umls/train.txt\n",
            "umls/\n",
            "Preprocessing umls...\n",
            "Found 5216 triples in train.txt\n",
            "Found 652 triples in valid.txt\n",
            "Found 661 triples in test.txt\n",
            "46 distinct relations\n",
            "135 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 661\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 661\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 5216\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 652\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 652\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 652\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: umls\n",
            "  num_entities: 135\n",
            "  num_relations: 46\n",
            "\n",
            "Downloading wn11\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1366k  100 1366k    0     0   297k      0  0:00:04  0:00:04 --:--:--  297k\n",
            "wn11/\n",
            "wn11/test.txt\n",
            "wn11/dev.txt\n",
            "wn11/train.txt\n",
            "Preprocessing wn11...\n",
            "Found 112581 triples in train.txt\n",
            "Found 5218 triples in valid.txt\n",
            "Found 21088 triples in test.txt\n",
            "11 distinct relations\n",
            "38588 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 10544\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_negatives.filename: test_negatives.del\n",
            "  files.test_negatives.size: 10544\n",
            "  files.test_negatives.split_type: test\n",
            "  files.test_negatives.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 9744\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.test_without_unseen_negatives.filename: test_without_unseen_negatives.del\n",
            "  files.test_without_unseen_negatives.size: 10002\n",
            "  files.test_without_unseen_negatives.split_type: test\n",
            "  files.test_without_unseen_negatives.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 112581\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 5218\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 2609\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_negatives.filename: valid_negatives.del\n",
            "  files.valid_negatives.size: 2609\n",
            "  files.valid_negatives.split_type: valid\n",
            "  files.valid_negatives.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 2412\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  files.valid_without_unseen_negatives.filename: valid_without_unseen_negatives.del\n",
            "  files.valid_without_unseen_negatives.size: 2468\n",
            "  files.valid_without_unseen_negatives.split_type: valid\n",
            "  files.valid_without_unseen_negatives.type: triples\n",
            "  name: wn11\n",
            "  num_entities: 38588\n",
            "  num_relations: 11\n",
            "\n",
            "Downloading CoDEx-S\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  209k  100  209k    0     0  77367      0  0:00:02  0:00:02 --:--:-- 77378\n",
            "codex-s/\n",
            "codex-s/test.txt\n",
            "codex-s/test_negatives.txt\n",
            "codex-s/train.txt\n",
            "codex-s/valid.txt\n",
            "codex-s/valid_negatives.txt\n",
            "Preprocessing codex-s...\n",
            "Found 32888 triples in train.txt\n",
            "Found 1827 triples in valid.txt\n",
            "Found 1828 triples in test.txt\n",
            "42 distinct relations\n",
            "2034 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 1828\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 1828\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 32888\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 1827\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 1827\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 1827\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: codex-s\n",
            "  num_entities: 2034\n",
            "  num_relations: 42\n",
            "\n",
            "Downloading CoDEx-M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1468k  100 1468k    0     0   245k      0  0:00:05  0:00:05 --:--:--  357k\n",
            "codex-m/\n",
            "codex-m/test.txt\n",
            "codex-m/test_negatives.txt\n",
            "codex-m/train.txt\n",
            "codex-m/valid.txt\n",
            "codex-m/valid_negatives.txt\n",
            "Preprocessing codex-m...\n",
            "Found 185584 triples in train.txt\n",
            "Found 10310 triples in valid.txt\n",
            "Found 10311 triples in test.txt\n",
            "51 distinct relations\n",
            "17050 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 10311\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 10311\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 185584\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 10310\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 10310\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 10310\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: codex-m\n",
            "  num_entities: 17050\n",
            "  num_relations: 51\n",
            "\n",
            "Downloading CoDEx-L\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 4258k  100 4258k    0     0   314k      0  0:00:13  0:00:13 --:--:--  395k\n",
            "codex-l/\n",
            "codex-l/test.txt\n",
            "codex-l/train.txt\n",
            "codex-l/valid.txt\n",
            "Preprocessing codex-l...\n",
            "Found 551193 triples in train.txt\n",
            "Found 30622 triples in valid.txt\n",
            "Found 30622 triples in test.txt\n",
            "69 distinct relations\n",
            "77951 distinct entities\n",
            "Writing relation and entity map...\n",
            "dataset:\n",
            "  files.entity_ids.filename: entity_ids.del\n",
            "  files.entity_ids.type: map\n",
            "  files.relation_ids.filename: relation_ids.del\n",
            "  files.relation_ids.type: map\n",
            "  files.test.filename: test.del\n",
            "  files.test.size: 30622\n",
            "  files.test.split_type: test\n",
            "  files.test.type: triples\n",
            "  files.test_without_unseen.filename: test_without_unseen.del\n",
            "  files.test_without_unseen.size: 30622\n",
            "  files.test_without_unseen.split_type: test\n",
            "  files.test_without_unseen.type: triples\n",
            "  files.train.filename: train.del\n",
            "  files.train.size: 551193\n",
            "  files.train.split_type: train\n",
            "  files.train.type: triples\n",
            "  files.train_sample.filename: train_sample.del\n",
            "  files.train_sample.size: 30622\n",
            "  files.train_sample.split_type: train\n",
            "  files.train_sample.type: triples\n",
            "  files.valid.filename: valid.del\n",
            "  files.valid.size: 30622\n",
            "  files.valid.split_type: valid\n",
            "  files.valid.type: triples\n",
            "  files.valid_without_unseen.filename: valid_without_unseen.del\n",
            "  files.valid_without_unseen.size: 30622\n",
            "  files.valid_without_unseen.split_type: valid\n",
            "  files.valid_without_unseen.type: triples\n",
            "  name: codex-l\n",
            "  num_entities: 77951\n",
            "  num_relations: 69\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre processing each datasest (Original, COMP and De-gend),\n",
        "After, preprocessing, we also get the embedding indexes which will later be used in score prediction."
      ],
      "metadata": {
        "id": "-ULiB4mc3KLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Khine/kge/data/preprocess/preprocess_default.py /content/drive/MyDrive/Khine/kge/data/ckbc/"
      ],
      "metadata": {
        "id": "btbdz46_Ty0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Khine/kge/data/preprocess/preprocess_default.py /content/drive/MyDrive/Khine/kge/data/ckbcComp"
      ],
      "metadata": {
        "id": "TZSjaWwbTeNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ../kge/data/preprocess/preprocess_default.py ../kge/data/ckbcDegender/"
      ],
      "metadata": {
        "id": "VvZmKUPEY0vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training individual models for each dataset.\n",
        "\n",
        "For example, if you want to transE on three dataset, you have to run the following."
      ],
      "metadata": {
        "id": "WbQly8CmPpyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kge start ../kge/train/transeOriginal.yaml"
      ],
      "metadata": {
        "id": "2EeOGvEpr6SI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kge start ../kge/train/transeDegender.yaml"
      ],
      "metadata": {
        "id": "oQ5q_CbSwwIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kge start ../kge/train/transeComp.yaml"
      ],
      "metadata": {
        "id": "kyUk5sQIVFwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# scores for each triple pair by indexing\n",
        "\n",
        "For example, below code is finding scores for both (man(s), IsA(p), nurse(o)) and (woman(s'),IsA(p),nurse(o)).\n",
        "\n",
        "Occupations used here are referenced from **WinoBias** occupation dataset.\n"
      ],
      "metadata": {
        "id": "Ur7KE1B_xsZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from kge.model import KgeModel\n",
        "from kge.util.io import load_checkpoint\n",
        "checkpoint = load_checkpoint('/content/drive/MyDrive/Khine/kge/local/experiments/20230109-121010-filtered/checkpoint_best.pt')\n",
        "model = KgeModel.create_from(checkpoint)\n",
        "\n",
        "s = torch.Tensor([868, 960,]).long()             # head indexes (man and woman)\n",
        "p = torch.Tensor([5, 5,]).long()             # relation indexes (IsA,IsA)\n",
        "o = torch.Tensor([1425, 1425,]).long()      # tail indexes(nurse)\n",
        "scores = model.score_spo(s, p, o, direction=o)\n",
        "print (model.score_spo(s, p, o, direction= \"s\")   )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnHaIqXmfFBw",
        "outputId": "594e9055-0036-4406-cdbe-6f80c3aa893c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading configuration of dataset /content/drive/MyDrive/Khine/kge/data/ckbcFiltered from /content/drive/MyDrive/Khine/kge/data/ckbcFiltered ...\n",
            "tensor([-4.5442, -2.2436], grad_fn=<ViewBackward>)\n"
          ]
        }
      ]
    }
  ]
}